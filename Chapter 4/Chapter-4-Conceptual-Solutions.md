# Chapter-4-Conceptual-Solutions

## Questions And Answers
Exercise 4.1: In Example 4.1, if ![$\pi$](https://render.githubusercontent.com/render/math?math=%24%5Cpi%24) is the equiprobable random policy, what is ![$q_{\pi}(11, \textrm{down})$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(11%2C%20%5Ctextrm%7Bdown%7D)%24)? What is ![$q_{\pi}(7, \textrm{down})$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(7%2C%20%5Ctextrm%7Bdown%7D)%24)?

First, note that the underlying assumptions of the 4x4 gridworld in Example 4.1 are: 1) the task is treated as undiscounted, and so ![$\gamma=1$](https://render.githubusercontent.com/render/math?math=%24%5Cgamma%3D1%24); 2) all transitions receive a reward of -1; and 3) all actions deterministically cause state transitions.

The action-value function for policy ![$\pi$](https://render.githubusercontent.com/render/math?math=%24%5Cpi%24) (denoted ![$q_{\pi}(s,a)$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(s%2Ca)%24)) is given by ![$q_{\pi}(s,a) = \mathbb{E}\[G_t \mid S_t=s, A_t=a\] = \sum_{s\!',r} p(s\!',r \mid s,a)\[r+\gamma v_{\pi}(s\!')\]$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(s%2Ca)%20%3D%20%5Cmathbb%7BE%7D%5BG_t%20%5Cmid%20S_t%3Ds%2C%20A_t%3Da%5D%20%3D%20%5Csum_%7Bs%5C!'%2Cr%7D%20p(s%5C!'%2Cr%20%5Cmid%20s%2Ca)%5Br%2B%5Cgamma%20v_%7B%5Cpi%7D(s%5C!')%5D%24) (Equation 4.6 in the text).

For ![$s=11$](https://render.githubusercontent.com/render/math?math=%24s%3D11%24) and ![$a=\textrm{down}$](https://render.githubusercontent.com/render/math?math=%24a%3D%5Ctextrm%7Bdown%7D%24), ![$s\!'=\textrm{Terminal}$](https://render.githubusercontent.com/render/math?math=%24s%5C!'%3D%5Ctextrm%7BTerminal%7D%24), ![$r=-1$](https://render.githubusercontent.com/render/math?math=%24r%3D-1%24), ![$p(s\!'=\textrm{Terminal},r=-1 \mid s=11,a=\textrm{down}) = 1$](https://render.githubusercontent.com/render/math?math=%24p(s%5C!'%3D%5Ctextrm%7BTerminal%7D%2Cr%3D-1%20%5Cmid%20s%3D11%2Ca%3D%5Ctextrm%7Bdown%7D)%20%3D%201%24), and thus ![$q_{\pi}(s=11,a=\textrm{down}) = p(s\!'=\textrm{Terminal},r=-1 \mid s=11,a=\textrm{down}) \[r + \gamma v_{\pi}(s\!'=\textrm{Terminal})\] = (1) \[-1 + 1(0)\] = -1$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(s%3D11%2Ca%3D%5Ctextrm%7Bdown%7D)%20%3D%20p(s%5C!'%3D%5Ctextrm%7BTerminal%7D%2Cr%3D-1%20%5Cmid%20s%3D11%2Ca%3D%5Ctextrm%7Bdown%7D)%20%5Br%20%2B%20%5Cgamma%20v_%7B%5Cpi%7D(s%5C!'%3D%5Ctextrm%7BTerminal%7D)%5D%20%3D%20(1)%20%5B-1%20%2B%201(0)%5D%20%3D%20-1%24).

For ![$s=7$](https://render.githubusercontent.com/render/math?math=%24s%3D7%24) and ![$a=\textrm{down}$](https://render.githubusercontent.com/render/math?math=%24a%3D%5Ctextrm%7Bdown%7D%24), ![$s\!'=11$](https://render.githubusercontent.com/render/math?math=%24s%5C!'%3D11%24), ![$r=-1$](https://render.githubusercontent.com/render/math?math=%24r%3D-1%24), ![$p(s\!'=11,r=-1 \mid s=7,a=\textrm{down}) = 1$](https://render.githubusercontent.com/render/math?math=%24p(s%5C!'%3D11%2Cr%3D-1%20%5Cmid%20s%3D7%2Ca%3D%5Ctextrm%7Bdown%7D)%20%3D%201%24), and thus ![$q_{\pi}(s=7,a=\textrm{down}) = p(s\!'=11,r=-1 \mid s=7,a=\textrm{down}) \[r + \gamma v_{\pi}(s\!'=11)\] = (1) \[-1 + 1(-14)\] = -15$](https://render.githubusercontent.com/render/math?math=%24q_%7B%5Cpi%7D(s%3D7%2Ca%3D%5Ctextrm%7Bdown%7D)%20%3D%20p(s%5C!'%3D11%2Cr%3D-1%20%5Cmid%20s%3D7%2Ca%3D%5Ctextrm%7Bdown%7D)%20%5Br%20%2B%20%5Cgamma%20v_%7B%5Cpi%7D(s%5C!'%3D11)%5D%20%3D%20(1)%20%5B-1%20%2B%201(-14)%5D%20%3D%20-15%24).

Exercise 4.8: Why does the optimal policy for the gamblerâ€™s problem have such a curious form? In particular, for capital of 50 it bets it all on one flip, but for capital of 51 it does not. Why is this a good policy?

The optimal policy for the gambler's problem shown in Figure 4.3 corresponds to the case ![$\gamma=1$](https://render.githubusercontent.com/render/math?math=%24%5Cgamma%3D1%24), ![$p_h=0.4$](https://render.githubusercontent.com/render/math?math=%24p_h%3D0.4%24) (i.e., an undiscounted game, where each coin flip is biased against the gambler); thus, the gambler maximizes the probability of winning by minimizing the number of flips.

With capital ![$s=50$](https://render.githubusercontent.com/render/math?math=%24s%3D50%24), the gambler can bet it all and have probability ![$p_h=0.4$](https://render.githubusercontent.com/render/math?math=%24p_h%3D0.4%24) of winning.  With capital $s=51$, the gambler can do better by betting 1, either losing (and still having a ![$p_h=0.4$](https://render.githubusercontent.com/render/math?math=%24p_h%3D0.4%24) chance of winning with a maximum bet) or winning and ending up with capital ![$s=52$](https://render.githubusercontent.com/render/math?math=%24s%3D52%24). With capital ![$s=52$](https://render.githubusercontent.com/render/math?math=%24s%3D52%24), the gambler can implement a similar strategy, betting 2 and either losing (and still having a ![$p_h=0.4$](https://render.githubusercontent.com/render/math?math=%24p_h%3D0.4%24) chance of winning with a maximum bet) or winning and ending up with capital ![$s=54$](https://render.githubusercontent.com/render/math?math=%24s%3D54%24). Once at capital ![$s=75$](https://render.githubusercontent.com/render/math?math=%24s%3D75%24), the gambler can bet 25, either losing (and still having a ![$p_h=0.4$](https://render.githubusercontent.com/render/math?math=%24p_h%3D0.4%24) chance of winning with a maximum bet) or winning and achieving the goal of capital ![$s=100$](https://render.githubusercontent.com/render/math?math=%24s%3D100%24).
